This assignment provides three data files which are a subset of the One Billion Word Language Modeling Benchmark.

Tasked to do n-gram language modeling.

Part 1 implements unigram, bigram, and trigram language models using Maximum Likelihood Estimation (MLE) without smoothing. The models handle out-of-vocabulary (OOV) words by replacing tokens that occur fewer than three times with a special <UNK> token.

Part 2 allows the use of smoothing with linear interpolation and creating of models that give the best values for the chosen hyperparameters.

To run the code, download the Part1.py and Part2.py files and open in your desired IDE.

Type the following on your terminal:

python Part1.py

For part 2 use: 

python Part2.py
