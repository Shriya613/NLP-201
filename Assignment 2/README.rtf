{\rtf1\ansi\ansicpg1252\cocoartf2820
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\froman\fcharset0 Times-Roman;\f1\fmodern\fcharset0 Courier;\f2\froman\fcharset0 Times-Bold;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf0 \expnd0\expndtw0\kerning0
Part 1 implements unigram, bigram, and trigram language models using Maximum Likelihood Estimation (MLE) without smoothing. The models handle out-of-vocabulary (OOV) words by replacing tokens that occur fewer than three times with a special 
\f1\fs26 <UNK>
\f0\fs24  token.\
Run code using:\
\

\f2\b python Part1.py\
\

\f0\b0 For part 2 use: \
\

\f2\b python Part2.py\
}